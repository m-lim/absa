{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspect based sentiment analysis\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjPE3oizKX9U",
    "outputId": "fc1ae757-46de-4a7f-da71-36797ffa4252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "[101, 1045, 3715, 2009, 2012, 2305, 1998, 13558, 2635, 1996, 11601, 2007, 2033, 2138, 1997, 1996, 2204, 6046, 2166, 1012, 102]\n",
      "['[CLS]', 'i', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.', '[SEP]']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-neu', 'O', 'O', 'O', 'O', 'O', 'O', 'B-pos', 'I-pos', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import re\n",
    "\n",
    "polarity_dict = {'positive':'pos', 'negative':'neg', 'neutral':'neu', 'conflict':'con'}\n",
    "\n",
    "def get_labels(sentence, tokens, aspect_list):\n",
    "  if len(aspect_list) == 0:\n",
    "    return ['O' for i in range(len(tokens))]\n",
    "\n",
    "  sentence = sentence.lower()\n",
    "  new_tokens = tokens[1:-1]\n",
    "  cur_pos = 0\n",
    "  cur_asp_idx = 0\n",
    "  ans = ['O']\n",
    "  for x in new_tokens:\n",
    "    cur_sub_word = x if x[:2]!='##' else x[2:]\n",
    "    #pattern = re.compile(cur_sub_word)\n",
    "    #match = pattern.search(sentence, cur_pos)\n",
    "    #s,e = match.span()\n",
    "    s = sentence.find(cur_sub_word, cur_pos)\n",
    "    e = s + len(cur_sub_word)\n",
    "    if cur_asp_idx < len(aspect_list) and s >= aspect_list[cur_asp_idx]['start'] and s<aspect_list[cur_asp_idx]['end']:\n",
    "      cur_char = 'B' if ans[-1]=='O' else 'I'\n",
    "      ans.append(f'{cur_char}-{polarity_dict[aspect_list[cur_asp_idx][\"polarity\"]]}')\n",
    "    else:\n",
    "      ans.append('O')\n",
    "    if cur_asp_idx < len(aspect_list) and s >= aspect_list[cur_asp_idx]['end']:\n",
    "      cur_asp_idx += 1\n",
    "    cur_pos = e\n",
    "  ans.append('O')\n",
    "  return ans\n",
    "\n",
    "\n",
    "my_sentence = \"I charge it at night and skip taking the cord with me because of the good battery life.\"\n",
    "polarity = ['neutral', 'positive']\n",
    "start_of_aspect = [41, 74]\n",
    "end_of_aspect = [45, 86]\n",
    "aspect_list = [{'polarity':'neutral', 'start':41, 'end':45}, {'polarity':'positive', 'start':74, 'end':86}]\n",
    "\n",
    "print(len(my_sentence))\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "input_ids = tokenizer.encode(my_sentence)\n",
    "subwords = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "print(input_ids)\n",
    "print(subwords)\n",
    "labels = get_labels(my_sentence, subwords, aspect_list)\n",
    "print(labels)\n",
    "assert len(input_ids) == len(labels)\n",
    "\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# a = 1/0\n",
    "# output = model(input_ids, type_ids, att_m)\n",
    "\n",
    "# final_layer = output.last_hidden_state\n",
    "# final_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLI3YD14OChL",
    "outputId": "db05851a-96cb-4bb9-8f7d-22988bd3abb0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3045/3045 [00:01<00:00, 1602.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file...\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import xmltodict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"Laptop_Train_v2.xml\", \"r\") as f:\n",
    "  obj = xmltodict.parse(f.read())\n",
    "\n",
    "obj = obj['sentences']['sentence']\n",
    "out_sid = []\n",
    "out_tokens = []\n",
    "out_labels = []\n",
    "for x in tqdm(obj, total=len(obj)):\n",
    "  sentence = x['text']\n",
    "  sent_id = x['@id']\n",
    "  aspect_list = []\n",
    "  if 'aspectTerms' in x.keys():\n",
    "    aspects = x['aspectTerms']['aspectTerm']\n",
    "    if type(aspects) != list:\n",
    "      aspects = [aspects]\n",
    "    for a in aspects:\n",
    "      aspect_list.append({'polarity':a['@polarity'], 'start':int(a['@from']), 'end':int(a['@to'])})\n",
    "    aspect_list.sort(key=lambda x: x['start'])\n",
    "  input_ids = tokenizer.encode(sentence)\n",
    "  subwords = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "  \n",
    "  labels = get_labels(sentence, subwords, aspect_list)\n",
    "  # print(sentence)\n",
    "  # print(subwords)\n",
    "  # print(aspect_list)\n",
    "  # print(labels)\n",
    "  # print()\n",
    "  assert len(labels) == len(subwords)\n",
    "  out_sid.append(sent_id)\n",
    "  out_tokens.append(input_ids)\n",
    "  out_labels.append(labels)\n",
    "\n",
    "print('Writing to file...')\n",
    "df = pd.DataFrame()\n",
    "df['sid'] = out_sid\n",
    "df['token_ids'] = out_tokens\n",
    "df['labels'] = out_labels\n",
    "df.to_csv('preproc.csv', index=False)\n",
    "print('DONE')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ProjPreprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
